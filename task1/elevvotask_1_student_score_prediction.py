# -*- coding: utf-8 -*-
"""ElevvoTask_1_Student_Score_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mJ8C6u2h7WgMc62cCSBQkZ37VJCwAAKY

**1. Importing the librairies**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""**2. Data collection and Processing**"""

# load the dataset
data = pd.read_csv('/content/StudentPerformanceFactors.csv')

# from google.colab import drive
# drive.mount('/content/drive')

data.shape

data.head()

print('Data Info:')
data.info()

# check the number of missing values
data.isnull().sum()

# Handle missing values

data["Teacher_Quality"].unique()

data["Parental_Education_Level"].unique()

data["Distance_from_Home"].unique()

data["Parental_Education_Level"].unique()

# replace missing values by the mode in the three colums: Teacher_Quality, Parental_Education_Level, Distance_from_Home
data["Teacher_Quality"] = data["Teacher_Quality"].fillna(data["Teacher_Quality"].mode()[0])
data["Parental_Education_Level"] = data["Parental_Education_Level"].fillna(data["Parental_Education_Level"].mode()[0])
data["Distance_from_Home"] = data["Distance_from_Home"].fillna(data["Distance_from_Home"].mode()[0])

# check if all missing values have been replaced
print(data.isnull().sum())

"""**Build a model to predict students' exam scores based on their study hours**"""

# create a dataframe with the concerned columns
df = data[['Hours_Studied', 'Exam_Score']]
X = df['Hours_Studied']
y = df['Exam_Score']

print(X)

print(y)

# Split in training and test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**Train the model**"""

# train the model
model = LogisticRegression()
model.fit(X_train.values.reshape(-1, 1), y_train)

# evaluate the model
y_pred = model.predict(X_test.values.reshape(-1, 1))
r_squared = model.score(X_test.values.reshape(-1, 1), y_test)
mae = np.mean(np.abs(y_pred - y_test))
mse = np.mean((y_pred - y_test)**2)
rmse = np.sqrt(mse)

print('R-squared:', r_squared)
print('Mean Absolute Error (MAE):', mae)
print('Mean Squared Error (MSE):', mse)
print('Root Mean Squared Error (RMSE):', rmse)

# add a scatter plot with a regression line
plt.figure(figsize=(10, 6))
sns.regplot(x=X_test, y=y_test)
plt.title('Hours studies vs Exam score')
plt.xlabel('Hours Studied')
plt.ylabel('Exam Score')
plt.show()

"""**Other visualisations**"""

data.columns

data.head()

# distribution graphs per column (for quantitative variables)
plt.figure(figsize=(15, 10))
for i, column in enumerate(['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', 'Tutoring_Sessions', 'Physical_Activity'], 1):
    plt.subplot(2, 3, i)
    sns.histplot(data[column], kde=True)
    plt.title(f"Distribution of {column}")

plt.tight_layout
plt.show()

# check the distribution of qualitative columns
plt.figure(figsize=(20, 15))
for i, column in enumerate(['Parental_Involvement', 'Access_to_Resources', 'Extracurricular_Activities', 'Motivation_Level', 'Family_Income','Teacher_Quality', 'School_Type', 'Peer_Influence', 'Learning_Disabilities','Parental_Education_Level', 'Distance_from_Home', 'Gender'], 1):
    plt.subplot(3, 4, i)
    sns.countplot(data=data, x=column)
    plt.title(f"Distribution of {column}", fontsize=10)
    plt.xticks(fontsize=8)
    plt.yticks(fontsize=8)

plt.tight_layout
plt.show()

# boxplot graphs per column (for quantitative variables)
plt.figure(figsize=(15, 10))
for i, column in enumerate(['Hours_Studied', 'Attendance', 'Sleep_Hours', 'Previous_Scores', 'Tutoring_Sessions', 'Physical_Activity'], 1):
    plt.subplot(2, 3, i)
    sns.boxplot(data[column])
    plt.title(f"Distribution of {column}")

plt.tight_layout
plt.show()

"""**Split the dataset into training and testing sets**"""

# prepare the data for splitting

# categorical data
ordinal_cols = ['Parental_Involvement', 'Access_to_Resources', 'Family_Income', 'Teacher_Quality','Motivation_Level']
nominal_cols = ['Gender', 'School_Type', 'Internet_Access', 'Extracurricular_Activities', 'Peer_Influence', 'Learning_Disabilities', 'Parental_Education_Level', 'Distance_from_Home']

# print unique values for all ordinal columns
for col in ordinal_cols:
    print(col, data[col].unique())

# print unique values for all nominal columns
for col in nominal_cols:
  print(col, data[col].unique())

# transform all ordinal column values to numbers
data['Parental_Involvement'] = data['Parental_Involvement'].map({'Low': 1, 'Medium': 2, 'High': 3})
data['Access_to_Resources'] = data['Access_to_Resources'].map({'Low':1, 'Medium':2, 'High':3})
data['Motivation_Level'] = data['Motivation_Level'].map({'Low':1, 'Medium':2, 'High':3})
data['Family_Income'] = data['Family_Income'].map({'Low':1, 'Medium':2, 'High':3})
data['Teacher_Quality'] = data['Teacher_Quality'].map({'Low':1, 'Medium':2, 'High':3})

# transform all nominal column values to numbers
data['Gender'] = data['Gender'].map({'Male':1, 'Female':2})
data['School_Type'] = data['School_Type'].map({'Public':1, 'Private':2})
data['Internet_Access'] = data['Internet_Access'].map({'No':1, 'Yes':2})
data['Extracurricular_Activities'] = data['Extracurricular_Activities'].map({'No':1, 'Yes':2})
data['Peer_Influence'] = data['Peer_Influence'].map({'Positive':3, 'Neutral':2, 'Negative':1})
data['Learning_Disabilities'] = data['Learning_Disabilities'].map({'No':2, 'Yes':1})
data['Parental_Education_Level'] = data['Parental_Education_Level'].map({'High School':1, 'College':2, 'Postgraduate':3})
data['Distance_from_Home'] = data['Distance_from_Home'].map({'Close':2, 'Far':1})

# print data information
data.info()

# drop Distance_from_Home column which has NAN
data = data.drop(columns=['Distance_from_Home'])

# split features and target as X and y
X = data.drop(columns=['Exam_Score'])
y = data['Exam_Score']

print(X)

print(y)

# splitting the data into training and test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**Train a linear regression model to estimate final scores**"""

# train a linear regression model
linear_model = LogisticRegression()
linear_model.fit(X_train, y_train)

"""**Visualize predictions and evaluate model performance**"""

# predict and evaluate
y_pred = linear_model.predict(X_test)

mae = np.mean(np.abs(y_pred - y_test))
mse = np.mean((y_pred - y_test)**2)
rmse = np.sqrt(mse)
r_squared = linear_model.score(X_test, y_test)

print("\n Test Metrics")
print(f"MAE : {mae:,.4f}")
print(f"MSE : {mse:,.4f}")
print(f"RMSE: {rmse:,.4f}")
print(f"r_squared  : {r_squared:,.4f}")

from numpy._core.defchararray import lower
# create plots
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
low, high = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())
plt.plot([low, high], [low, high], linewidth=2, color='red')
plt.xlabel('Actual Exam Score')
plt.ylabel('Predicted Exam Score')
plt.title('Actual vs. Predicted Exam Scores')
plt.grid(True)
plt.show()

residuals = y_test - y_pred
plt.figure(figsize=(10, 6))
plt.hist(residuals, bins=30, edgecolor='black')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.grid(True)
plt.title('Distribution of Residuals')
plt.show()

plt.figure(figsize=(10,6))
plt.scatter(y_pred, residuals, alpha=0.7)
plt.axhline(0, linestyle="--", linewidth=2)
plt.xlabel("Predicted")
plt.ylabel("Residual")
plt.title("Residuals vs Predicted")
plt.grid(True)
plt.show()