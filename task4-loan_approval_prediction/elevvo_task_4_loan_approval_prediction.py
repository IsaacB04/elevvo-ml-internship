# -*- coding: utf-8 -*-
"""Elevvo Task 4: loan approval prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T0ZRJ4BtfDlt5y2qxfP52XPghKmZfu0e

**Import the librairies and load the data**
"""

# import the librairies
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
import joblib
import warnings
warnings.filterwarnings('ignore')

# load the data
df = pd.read_csv('/content/loan_approval_dataset.csv')

print('data shape:', df.shape)

df.head()

"""**EDA**"""

print('Data info:')
df.info()

# find the number of null values
 df.isnull().sum()

# Inspect raw columns
df.columns

# remove white spaces in columns names
df.columns = df.columns.str.strip()

df.columns

print(f"distribution of 'loan approval status'")
print(df['loan_status'].value_counts())
print(df['loan_status'].value_counts(normalize=True))

"""**Create visuals**"""

# distribution of loan status
plt.figure(figsize=(6,4))
sns.countplot(x='loan_status', data=df, palette='Set2')
plt.xlabel('Loan Status')
plt.ylabel('Count')
plt.title('Distribution of Loan Status')
plt.show()

# boxplots
plt.figure(figsize=(15,10))

for i, col in enumerate(['loan_id', 'no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score','residential_assets_value',
                         'commercial_assets_value','luxury_assets_value', 'bank_asset_value'], 1):
    plt.subplot(4, 3, i)
    sns.boxplot(df[col], color='skyblue')
    plt.title(col)

plt.tight_layout()
plt

# distribution graphs of numerical columns
plt.figure(figsize=(15,10))

for i, col in enumerate(['loan_id', 'no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score', 'residential_assets_value', 'commercial_assets_value',
       'luxury_assets_value', 'bank_asset_value'], 1):
  plt.subplot(4, 3, i)
  sns.histplot(df[col], kde=True, palette='Set2')
  plt.title(col)
  plt.xlabel(col)

plt.tight_layout()
plt.show

cols = ["education", "self_employed"]

fig, axes = plt.subplots(1, 2, figsize=(10, 4))
for i, col in enumerate(cols):
    counts = df[col].value_counts(dropna=False)
    sns.barplot(x=counts.index, y=counts.values, ax=axes[i], palette="Set2")
    axes[i].set_title(col)
    axes[i].set_xlabel(col)
    axes[i].set_ylabel("Count")
fig.tight_layout()
plt.show()

# correlation heatmap
num_cols = ['loan_id', 'no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score', 'residential_assets_value', 'commercial_assets_value',
       'luxury_assets_value', 'bank_asset_value']
corr = pd.concat([df[num_cols], df['loan_status'].map({'Approved': 1, 'Rejected': 0})],  axis=1).corr()
plt.figure(figsize=(12, 10))
sns.heatmap(corr, annot=True, cmap='Spectral_r', cbar_kws={'shrink': 0.6})
plt.title('Correlation Heatmap')
plt.show

df['loan_status'].unique()

# normalize string in 'loan status': strip spaces, collapse whitespace, unify case
df['loan_status'] = df['loan_status'].str.strip()
df['loan_status'] = df['loan_status'].str.replace(r"\s+", " ", regex=True)
df['loan_status'] = df['loan_status'].str.title()

"""**Preprocessing**"""

# remap loan status
df['loan_status'] = df['loan_status'].map({'Approved': 1, 'Rejected': 0})

df['loan_status'].unique()

# split dataset into train and test sets
X = df.drop(columns=['loan_id', 'loan_status'])
y = df['loan_status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# preprocessor
numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = ['education', 'self_employed']
preprocessor = ColumnTransformer([
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(), categorical_features)
    ])

print(y)

print(X)

"""**Modeling**

predicting with logistic regression, RandomizedSearchCV and SMOTE
"""

# logistic regression, RandomizedSearchCV and SMOTE
log_pipe = ImbPipeline(steps=[
    ("preprocessor", preprocessor),
    ("smote", SMOTE(random_state=42)),
    ("classifier", LogisticRegression(random_state=42, max_iter=1000))
])

log_param_grid = {
    "classifier__C": np.logspace(-4, 4, 20),
    "classifier__penalty": ["l1", "l2"],
    "classifier__solver": ["liblinear", "saga"],
}

log_search = RandomizedSearchCV(
    estimator=log_pipe,
    param_distributions=log_param_grid,
    n_iter=20,
    cv=5,
    scoring="f1",
    random_state=42,
    n_jobs=-1,
    verbose=1,
)

log_search.fit(X_train, y_train)
best_log = log_search.best_estimator_
print("Best Logistic Params:", log_search.best_params_)

# evaluate
y_pred_log = best_log.predict(X_test)
y_proba_log = best_log.predict_proba(X_test)[:, 1]
print("\nLogistic Regression (SMOTE and Tuned)")
print(classification_report(y_test, y_pred_log, target_names=['Rejected', 'Approved']))
log_auc = roc_auc_score(y_test, y_proba_log)          # <-- fixed name
print(f"ROC-AUC: {log_auc:.4f}")

cm_log = confusion_matrix(y_test, y_pred_log)
sns.heatmap(cm_log, annot=True, fmt='d', cmap='Blues',
            cbar_kws={'shrink': 0.6},
            xticklabels=['Rejected', 'Approved'],
            yticklabels=['Rejected', 'Approved'])
plt.title('Confusion Matrix: Logistic Regression')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

# Decision tree with Random search and SMOTE
dt_pipe = ImbPipeline(steps=[
    ("preprocessor", preprocessor),
    ("smote", SMOTE(random_state=42)),
    ("classifier", DecisionTreeClassifier(random_state=42))
])

dt_param_grid = {
    "classifier__max_depth": [3, 5, 7, 10, 15, None],
    "classifier__min_samples_split": [2, 5, 10, 20],
    "classifier__min_samples_leaf": [1, 2, 5, 10],
    "classifier__criterion": ["gini", "entropy"],
}

dt_random_search = RandomizedSearchCV(
    estimator=dt_pipe,
    param_distributions=dt_param_grid,
    n_iter=30,
    cv=5,
    scoring="f1",
    random_state=42,
    n_jobs=-1,
    verbose=1,
)

dt_random_search.fit(X_train, y_train)
best_dt = dt_random_search.best_estimator_
print("Best Decision Tree Params:", dt_random_search.best_params_)

# evaluate
y_pred_dt = best_dt.predict(X_test)
y_proba_dt = best_dt.predict_proba(X_test)[:, 1]
print("\nDecision Tree (SMOTE and Tuned)")
print(classification_report(y_test, y_pred_dt, target_names=['Rejected', 'Approved']))  # <-- fixed y_pred_dt
dt_auc = roc_auc_score(y_test, y_proba_dt)
print(f"ROC-AUC: {dt_auc:.4f}")

cm_dt = confusion_matrix(y_test, y_pred_dt)          # <-- fixed cm for DT
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues',
            cbar_kws={'shrink': 0.6},
            xticklabels=['Rejected', 'Approved'],
            yticklabels=['Rejected', 'Approved'])
plt.title('Confusion Matrix: Decision Tree')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

"""**Compare the models and determine feature importance**"""

# compare the models
models = pd.DataFrame({
    'Model': ["Logistic Regression", "Decision Tree"],
    'ROC-AUC': [log_auc, dt_auc],                     # <-- now both exist
    'Best Params': [log_search.best_params_, dt_random_search.best_params_],
})

print('\nModel Comparison')
print(models)

# feature importance
# extract feature names after one-hot encoder
ohe = best_dt.named_steps['preprocessor'].named_transformers_['cat']
cat_features = ohe.get_feature_names_out(categorical_features)
feature_names = numeric_features + list(cat_features)

# coefficients/Importance
if hasattr(best_dt.named_steps['classifier'], 'coef_'):
  importances = np.abs(best_dt.named_steps['classifier'].coef_[0])
  title = 'Logistic Regression Feature Importance'
else:
  importances = best_dt.named_steps['classifier'].feature_importances_
  title = 'Decision Tree Feature Importance'

feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values('Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance.head(10), palette='Set2')
plt.title(title)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()